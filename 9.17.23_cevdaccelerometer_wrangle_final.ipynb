{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/cluster/dnax/jars/dnanexus-api-0.1.0-SNAPSHOT-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/cluster/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 02:33:01.287 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2023-09-18 02:33:02.369 WARN  Utils:69 - Service 'org.apache.spark.network.netty.NettyBlockTransferService' could not bind on port 43000. Attempting port 43001.\n",
      "2023-09-18 02:33:02.608 WARN  MetricsReporter:84 - No metrics configured for reporting\n",
      "2023-09-18 02:33:02.609 WARN  LineProtoUsageReporter:48 - Telegraf configurations: url [metrics.push.telegraf.hostport], user [metrics.push.telegraf.user] or password [metrics.push.telegraf.password] missing.\n",
      "2023-09-18 02:33:02.610 WARN  MetricsReporter:117 - metrics.scraping.httpserver.port\n"
     ]
    }
   ],
   "source": [
    "#run pip install fancyimpute\n",
    "#launch spark \n",
    "import pyspark\n",
    "import dxpy\n",
    "import dxdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from fancyimpute import IterativeImputer\n",
    "from scipy.stats import chi2_contingency\n",
    "sc = pyspark.SparkContext()\n",
    "spark = pyspark.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prep database \n",
    "dispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\n",
    "dispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prep dataset\n",
    "dataset = dxdata.load_dataset(id=dispensed_dataset_id)\n",
    "participant = dataset[\"participant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 02:33:13.900 WARN  ShellBasedUnixGroupsMapping:210 - unable to return groups for user pQgXFYVQy25Yk5kKPgYB9pJ2z5qgXPJpBjPXZkgf__project-GG7jpPjJ4VK0VKqV89494XV5\n",
      "PartialGroupNameException The user name 'pQgXFYVQy25Yk5kKPgYB9pJ2z5qgXPJpBjPXZkgf__project-GG7jpPjJ4VK0VKqV89494XV5' is not found. id: ‘pQgXFYVQy25Yk5kKPgYB9pJ2z5qgXPJpBjPXZkgf__project-GG7jpPjJ4VK0VKqV89494XV5’: no such user\n",
      "id: ‘pQgXFYVQy25Yk5kKPgYB9pJ2z5qgXPJpBjPXZkgf__project-GG7jpPjJ4VK0VKqV89494XV5’: no such user\n",
      "\n",
      "\tat org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:294)\n",
      "\tat org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:207)\n",
      "\tat org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:97)\n",
      "\tat org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:51)\n",
      "\tat org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupList(Groups.java:387)\n",
      "\tat org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:321)\n",
      "\tat org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:270)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985)\n",
      "\tat org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946)\n",
      "\tat org.apache.hadoop.security.Groups.getGroups(Groups.java:228)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1734)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1722)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:517)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:254)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3650)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMetaStoreClient(Hive.java:3696)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.lambda$getMSC$0(Hive.java:3770)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3768)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3682)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getDatabase(Hive.java:1600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.databaseExists(Hive.java:1588)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$databaseExists$1(HiveClientImpl.scala:396)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:305)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:236)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:235)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:285)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:396)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:150)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:170)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:168)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:61)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:119)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:119)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupGlobalTempView(SessionCatalog.scala:940)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTempViews$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveTempViews$$lookupTempView(Analyzer.scala:950)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTempViews$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveTempViews$$lookupAndResolveTempView(Analyzer.scala:963)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTempViews$$anonfun$apply$12.applyOrElse(Analyzer.scala:901)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTempViews$$anonfun$apply$12.applyOrElse(Analyzer.scala:899)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$3(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:138)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1122)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1121)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.OrderPreservingUnaryNode.mapChildren(LogicalPlan.scala:206)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren(TreeNode.scala:1148)\n",
      "\tat org.apache.spark.sql.catalyst.trees.BinaryLike.mapChildren$(TreeNode.scala:1147)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.Join.mapChildren(basicLogicalOperators.scala:390)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$2(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1122)\n",
      "\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1121)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.OrderPreservingUnaryNode.mapChildren(LogicalPlan.scala:206)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsUpWithPruning$1(AnalysisHelper.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning(AnalysisHelper.scala:134)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsUpWithPruning$(AnalysisHelper.scala:130)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUpWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveTempViews$.apply(Analyzer.scala:899)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1164)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:1131)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:211)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n",
      "\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n",
      "\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:208)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:200)\n",
      "\tat scala.collection.immutable.List.foreach(List.scala:431)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:200)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:222)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:218)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:167)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:218)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:182)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:179)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)\n",
      "\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:179)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:203)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:202)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:75)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:183)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:183)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:75)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:73)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:65)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "#pull all relevant columns\n",
    "field_names = [\"eid\", \"p31\", \"p22189\", \"p21000_i0\", \"p21001_i0\", 'p21001_i1', 'p21003_i0',  'p21003_i1', \"p1558_i0\",\"p1558_i1\", \"p20002_i0\",  \"p131298\", \"p6150_i0\", \"p131286\", \"p131294\", \"p130814\", \"p130706\", \"p130708\", \"p53_i0\",  \"p53_i1\",  \"p130892\", \"p130894\", \"p130896\", \"p2050_i0\", \"p2060_i0\",  \"p2050_i1\",  \"p130838\", \"p131056\", \"p131058\", \"p131180\", \"p131360\", \"p131362\", \"p131364\", \"p131366\", \"p131368\", \"p131370\", \"p131372\", \"p131374\", \"p131376\", \"p131378\", \"p22032_i0\", 'p21001_i1', 'p1558_i1', 'p21003_i1',  'p21003_i1', 'p20116_i0', 'p20116_i1', 'p20003_i0', 'p1160_i0', 'p20003_i1', 'p1160_i1', 'p1070_i0', 'p1070_i1', 'p1080_i0', 'p1080_i1', 'p1120_i0', 'p1120_i1', 'p110005', 'p90051' , 'p90016', 'p90017', 'p90185', 'p90187', 'p90012', 'p90010', 'p90011', 'p6142_i0' , 'p134_i0', 'p131354', 'p131306', 'p40046_i0', 'p40047_i0', 'p40048_i0', 'p40049_i0', 'p90027', 'p90028', 'p90029', 'p90030', 'p90031', 'p90032', 'p90033', 'p90034', 'p90035', 'p90036', 'p90037', 'p90038', 'p90039', 'p90040', 'p90041', 'p90042', 'p90043', 'p90044', 'p90045', 'p90046', 'p90047', 'p90048', 'p90049', 'p90050', 'p90051', 'p40030_i0', 'p40031_i0', 'p40032_i0', 'p40033_i0', 'p6146_i0']\n",
    "df = participant.retrieve_fields(names=field_names, engine=dxdata.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-18 02:33:44.730 WARN  package:69 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/spark/python/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n",
      "/cluster/spark/python/pyspark/sql/pandas/conversion.py:194: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    }
   ],
   "source": [
    "#create pandas dataframe\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that pandas conversion worked - this is the full UKBB rows of px\n",
    "#pdf.head(10)\n",
    "len(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103660"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop any row/participant who does not have lifestyle data\n",
    "#pdf_lifestyle = pdf.dropna(subset=['p20116_i0',  'p1558_i0', 'p1160_i0', 'p1070_i0', 'p1080_i0', 'p1120_i0', 'p2050_i0'])\n",
    "#drop any row/participant who does not have wear duration data, aka accelerometer data\n",
    "pdf_lifestyle = pdf.dropna(subset=['p90051'])\n",
    "#check DF length\n",
    "len(pdf_lifestyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accelerometer cohort and quality control below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with less than 72 hours of wear time 97123\n"
     ]
    }
   ],
   "source": [
    "pdf_lifestyle = pdf[pdf['p90051'] >= 3.0]\n",
    "print('after dropping px with less than 72 hours of wear time', len(pdf_lifestyle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with poor calibration (outer) 97119\n"
     ]
    }
   ],
   "source": [
    "pdf_lifestyle = pdf_lifestyle[pdf_lifestyle['p90016'] == 1]\n",
    "print('after dropping px with poor calibration (outer)', len(pdf_lifestyle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with poor calibration (self) 96956\n"
     ]
    }
   ],
   "source": [
    "pdf_lifestyle = pdf_lifestyle[pdf_lifestyle['p90017'] == 1]\n",
    "print('after dropping px with poor calibration (self)', len(pdf_lifestyle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with more than 1% clips 96956\n"
     ]
    }
   ],
   "source": [
    "pdf_lifestyle['clip_perc'] = pdf_lifestyle['p90185']/pdf_lifestyle['p90187']\n",
    "pdf_lifestyle['clip_perc'].head(10)\n",
    "pdf_lifestyle = pdf_lifestyle[pdf_lifestyle['clip_perc'] <= 0.01]\n",
    "print('after dropping px with more than 1% clips', len(pdf_lifestyle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with avg acceleration > 100 mg 96949\n"
     ]
    }
   ],
   "source": [
    "pdf_lifestyle = pdf_lifestyle[pdf_lifestyle['p90012'] <= 100]\n",
    "print('after dropping px with avg acceleration > 100 mg', len(pdf_lifestyle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accelerometer quality check completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pID</th>\n",
       "      <th>male</th>\n",
       "      <th>tdi</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bmi_1</th>\n",
       "      <th>age_i0</th>\n",
       "      <th>age_i1</th>\n",
       "      <th>alc_freq</th>\n",
       "      <th>alc_freq_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pa_time_21</th>\n",
       "      <th>pa_time_22</th>\n",
       "      <th>pa_time_23</th>\n",
       "      <th>pa_time_24</th>\n",
       "      <th>pa_sleep_day_hour</th>\n",
       "      <th>pa_sed_day_hour</th>\n",
       "      <th>pa_light_day_hour</th>\n",
       "      <th>pa_mv_day_hour</th>\n",
       "      <th>gov_assistance</th>\n",
       "      <th>clip_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5545411</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>28.8906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.82</td>\n",
       "      <td>15.90</td>\n",
       "      <td>15.48</td>\n",
       "      <td>8.51</td>\n",
       "      <td>0.96,0.97,0.95,0.96,1,1,0.95,0.57,0.17,0.07,0,...</td>\n",
       "      <td>0.01,0.03,0.05,0.04,0,0,0.01,0.34,0.62,0.45,0....</td>\n",
       "      <td>0.03,0,0,0,0,0,0.04,0.09,0.21,0.35,0.33,0.22,0...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0.13,0.15,0.34,0.16,0,0.02,0...</td>\n",
       "      <td>[-7]</td>\n",
       "      <td>3.292736e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5180517</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>22.7933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33.53</td>\n",
       "      <td>28.41</td>\n",
       "      <td>31.26</td>\n",
       "      <td>32.41</td>\n",
       "      <td>0.98,1,1,1,1,1,1,0.44,0.02,0.14,0,0,0.04,0.12,...</td>\n",
       "      <td>0.02,0,0,0,0,0,0,0.46,0.52,0.22,0.28,0.33,0.5,...</td>\n",
       "      <td>0,0,0,0,0,0,0,0.11,0.46,0.58,0.57,0.57,0.35,0....</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0.05,0.15,0.1,0.1,0.13,0.07,...</td>\n",
       "      <td>[-7]</td>\n",
       "      <td>3.599349e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3530112</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>26.6137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.45</td>\n",
       "      <td>14.58</td>\n",
       "      <td>7.09</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1,0.99,1,1,1,0.85,0.34,0.47,0.1,0,0,0,0,0,0,0,...</td>\n",
       "      <td>0,0.01,0,0,0,0.03,0.15,0.07,0.15,0.08,0.05,0.4...</td>\n",
       "      <td>0,0,0,0,0,0.11,0.29,0.46,0.75,0.87,0.78,0.56,0...</td>\n",
       "      <td>0,0,0,0,0,0,0.22,0,0,0.06,0.18,0.04,0,0.02,0.0...</td>\n",
       "      <td>[-7]</td>\n",
       "      <td>5.219251e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3176117</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>20.0918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>32.56</td>\n",
       "      <td>38.86</td>\n",
       "      <td>36.33</td>\n",
       "      <td>29.51</td>\n",
       "      <td>0.47,0.5,0.45,0.4,0.51,0.44,0.4,0.43,0.46,0.43...</td>\n",
       "      <td>0.19,0.23,0.35,0.25,0.27,0.18,0.1,0.06,0.12,0....</td>\n",
       "      <td>0.28,0.18,0.2,0.31,0.22,0.39,0.5,0.5,0.4,0.19,...</td>\n",
       "      <td>0.06,0.08,0,0.04,0,0,0,0,0.02,0.04,0,0,0.02,0....</td>\n",
       "      <td>[-7]</td>\n",
       "      <td>4.263014e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3429176</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.93</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>23.2577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39.91</td>\n",
       "      <td>22.84</td>\n",
       "      <td>12.52</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.73,1,1,1,1,0.98,0.88,0.84,0.66,0.2,0.14,0.05...</td>\n",
       "      <td>0.09,0,0,0,0,0,0,0.11,0.18,0.36,0.42,0.32,0.31...</td>\n",
       "      <td>0.18,0,0,0,0,0.02,0.12,0.05,0.16,0.44,0.45,0.6...</td>\n",
       "      <td>0,0,0,0,0,0,0,0,0,0,0,0,0.14,0.01,0.02,0.04,0....</td>\n",
       "      <td>[-7]</td>\n",
       "      <td>9.191687e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pID  male   tdi  ethnicity      bmi  bmi_1  age_i0  age_i1  alc_freq  \\\n",
       "0   5545411     1 -4.62     1001.0  28.8906    NaN      59     NaN       3.0   \n",
       "1   5180517     0 -0.42     1001.0  22.7933    NaN      52     NaN       5.0   \n",
       "8   3530112     0 -2.74     1001.0  26.6137    NaN      52     NaN       5.0   \n",
       "11  3176117     0 -0.36     1001.0  20.0918    NaN      50     NaN       2.0   \n",
       "13  3429176     0 -1.93     3001.0  23.2577    NaN      47     NaN       3.0   \n",
       "\n",
       "    alc_freq_1  ... pa_time_21 pa_time_22 pa_time_23 pa_time_24  \\\n",
       "0          NaN  ...       9.82      15.90      15.48       8.51   \n",
       "1          NaN  ...      33.53      28.41      31.26      32.41   \n",
       "8          NaN  ...      18.45      14.58       7.09       3.58   \n",
       "11         NaN  ...      32.56      38.86      36.33      29.51   \n",
       "13         NaN  ...      39.91      22.84      12.52      18.10   \n",
       "\n",
       "                                    pa_sleep_day_hour  \\\n",
       "0   0.96,0.97,0.95,0.96,1,1,0.95,0.57,0.17,0.07,0,...   \n",
       "1   0.98,1,1,1,1,1,1,0.44,0.02,0.14,0,0,0.04,0.12,...   \n",
       "8   1,0.99,1,1,1,0.85,0.34,0.47,0.1,0,0,0,0,0,0,0,...   \n",
       "11  0.47,0.5,0.45,0.4,0.51,0.44,0.4,0.43,0.46,0.43...   \n",
       "13  0.73,1,1,1,1,0.98,0.88,0.84,0.66,0.2,0.14,0.05...   \n",
       "\n",
       "                                      pa_sed_day_hour  \\\n",
       "0   0.01,0.03,0.05,0.04,0,0,0.01,0.34,0.62,0.45,0....   \n",
       "1   0.02,0,0,0,0,0,0,0.46,0.52,0.22,0.28,0.33,0.5,...   \n",
       "8   0,0.01,0,0,0,0.03,0.15,0.07,0.15,0.08,0.05,0.4...   \n",
       "11  0.19,0.23,0.35,0.25,0.27,0.18,0.1,0.06,0.12,0....   \n",
       "13  0.09,0,0,0,0,0,0,0.11,0.18,0.36,0.42,0.32,0.31...   \n",
       "\n",
       "                                    pa_light_day_hour  \\\n",
       "0   0.03,0,0,0,0,0,0.04,0.09,0.21,0.35,0.33,0.22,0...   \n",
       "1   0,0,0,0,0,0,0,0.11,0.46,0.58,0.57,0.57,0.35,0....   \n",
       "8   0,0,0,0,0,0.11,0.29,0.46,0.75,0.87,0.78,0.56,0...   \n",
       "11  0.28,0.18,0.2,0.31,0.22,0.39,0.5,0.5,0.4,0.19,...   \n",
       "13  0.18,0,0,0,0,0.02,0.12,0.05,0.16,0.44,0.45,0.6...   \n",
       "\n",
       "                                       pa_mv_day_hour gov_assistance  \\\n",
       "0   0,0,0,0,0,0,0,0,0,0.13,0.15,0.34,0.16,0,0.02,0...           [-7]   \n",
       "1   0,0,0,0,0,0,0,0,0,0.05,0.15,0.1,0.1,0.13,0.07,...           [-7]   \n",
       "8   0,0,0,0,0,0,0.22,0,0,0.06,0.18,0.04,0,0.02,0.0...           [-7]   \n",
       "11  0.06,0.08,0,0.04,0,0,0,0,0.02,0.04,0,0,0.02,0....           [-7]   \n",
       "13  0,0,0,0,0,0,0,0,0,0,0,0,0.14,0.01,0.02,0.04,0....           [-7]   \n",
       "\n",
       "       clip_perc  \n",
       "0   3.292736e-05  \n",
       "1   3.599349e-06  \n",
       "8   5.219251e-06  \n",
       "11  4.263014e-06  \n",
       "13  9.191687e-07  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename columns\n",
    "pdf_rename = pdf_lifestyle.rename(columns={'eid': 'pID', 'p31': 'male', 'p22189': 'tdi', 'p21000_i0': 'ethnicity', 'p21001_i0': 'bmi', 'p21001_i1': 'bmi_1', 'p1558_i0': 'alc_freq', 'p1558_i1': 'alc_freq_1', 'p20002_i0': 'sr_illness', 'p21003_i0': 'age_i0', 'p21003_i1': 'age_i1',  'p131298': 'i21_date', 'p6150_i0': 'vasc_diag', 'p131298': 'i21_date', 'p131286': 'i10_date', 'p131294': 'i15_date', 'p130814': 'e78_date', 'p130706': 'e10_date', 'p130708': 'e11_date', 'p53_i0': 'date_i0', 'p53_i1': 'date_i1', 'p41271': 'icd9', 'p41270': 'icd10', 'p130892': 'f31_date',  'p130894': 'f32_date', 'p130896': 'f33_date', 'p2050_i0': 'phq2_1', 'p130838': 'f01_date', 'p131056': 'g45_date', 'p131058': 'g46_date', 'p131180': 'h34_date', 'p131360': 'i60_date', 'p131362': 'i61_date', 'p131364': 'i62_date', 'p131366': 'i63_date', 'p131368': 'i64_date', 'p131370': 'i65_date', 'p131372': 'i66_date', 'p131374': 'i67_date', 'p131376': 'i68_date', 'p131378': 'i69_date', 'p20116_i0': 'smok_stat', \"p20116_i1\": 'smok_stat_1', 'p1160_i0': 'sleep', 'p1160_i1': 'sleep_1', 'p1070_i0':'tv', 'p1070_i1':'tv_1', 'p1080_i0':'computer', 'p1080_i1':'computer_1', 'p1120_i0': 'mobile phone', 'p1120_i1': 'mobile phone_1', 'p20510': 'phq2_1_1', 'p22032_i0': 'ipaq', 'p2050_i1': 'phq2_1_followup', 'p90012': 'aac_overall_avg', 'p90185': 'acc_exceed8g_aftercal', 'p90187': 'acc_total_data_read', 'p90017': 'acc_calib_own', 'p90016': 'acc_calib_all', 'p90051': 'acc_weartime', 'p90010': 'acc_start_date', 'p90011': 'acc_end_date', 'p6142_i0': 'employ_status',  'p131354': 'i50_date', 'p131306': 'i25_date', 'p40046_i0': 'pa_sleep_over_avg', 'p40047_i0': 'pa_seden_over_avg', 'p40048_i0': 'pa_light_over_avg',  'p40049_i0': 'pa_mv_over_avg', 'p40049_i0': 'pa_mv_over_avg', 'p90027':'pa_time_1', 'p90028':'pa_time_2', 'p90029':'pa_time_3', 'p90030':'pa_time_4', 'p90031':'pa_time_5', 'p90032':'pa_time_6', 'p90033':'pa_time_7', 'p90034':'pa_time_8', 'p90035':'pa_time_9', 'p90036':'pa_time_10', 'p90037':'pa_time_11', 'p90038':'pa_time_12', 'p90039':'pa_time_13', 'p90040':'pa_time_14', 'p90041':'pa_time_15', 'p90042':'pa_time_16', 'p90043':'pa_time_17', 'p90044':'pa_time_18', 'p90045':'pa_time_19', 'p90046':'pa_time_20', 'p90047':'pa_time_21', 'p90048':'pa_time_22', 'p90049':'pa_time_23', 'p90050':'pa_time_24', 'p90051': 'pa_sum_wear', 'p40030_i0': 'pa_sleep_day_hour', 'p40031_i0': 'pa_sed_day_hour', 'p40032_i0': 'pa_light_day_hour', 'p40033_i0': 'pa_mv_day_hour', 'p6146_i0': 'gov_assistance'})\n",
    "#check that rename worked\n",
    "pdf_rename.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4.66\n",
       "1      2.15\n",
       "8      5.36\n",
       "11    30.74\n",
       "13    11.81\n",
       "Name: pa_time_1, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that rename worked\n",
    "pdf_rename['pa_time_1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     584.0208\n",
       "1     475.6176\n",
       "8     603.6336\n",
       "11    442.9296\n",
       "Name: pa_sleep_convert, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert physical activity (pa) data to numeric\n",
    "pdf_rename['pa_sum_wear'] = pd.to_numeric(pdf_rename['pa_sum_wear'], errors='coerce')\n",
    "pdf_rename['pa_seden_over_avg'] = pd.to_numeric(pdf_rename['pa_seden_over_avg'], errors='coerce')\n",
    "pdf_rename['pa_sleep_over_avg'] = pd.to_numeric(pdf_rename['pa_sleep_over_avg'], errors='coerce')\n",
    "pdf_rename['pa_light_over_avg'] = pd.to_numeric(pdf_rename['pa_light_over_avg'], errors='coerce')\n",
    "pdf_rename['pa_mv_over_avg'] = pd.to_numeric(pdf_rename['pa_mv_over_avg'], errors='coerce')\n",
    "#; convert total wear value/day to minutes\n",
    "pdf_rename['pa_sum_wear_min'] = pdf_rename['pa_sum_wear']*24*60\n",
    "#convert PA type to minutes/day/week = daily minutes in PA type\n",
    "pdf_rename['pa_sed_convert'] = (pdf_rename['pa_sum_wear_min']*pdf_rename['pa_seden_over_avg'])/pdf_rename['pa_sum_wear']\n",
    "pdf_rename['pa_sleep_convert'] = (pdf_rename['pa_sum_wear_min']*pdf_rename['pa_sleep_over_avg'])/pdf_rename['pa_sum_wear']\n",
    "pdf_rename['pa_light_convert'] = (pdf_rename['pa_sum_wear_min']*pdf_rename['pa_light_over_avg'])/pdf_rename['pa_sum_wear']\n",
    "pdf_rename['pa_mv_convert'] = (pdf_rename['pa_sum_wear_min']*pdf_rename['pa_mv_over_avg'])/pdf_rename['pa_sum_wear']\n",
    "#check conversion\n",
    "pdf_rename['pa_sleep_convert'].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert ethnicity data to be workable\n",
    "pdf_rename['ethnicity'].dtype\n",
    "pdf_rename['ethnicity'] = pd.to_numeric(pdf_rename['ethnicity'], errors='coerce')\n",
    "pdf_rename['ethnicity'].dtype\n",
    "for index, row in pdf_rename.iterrows():\n",
    "    if row['ethnicity'] == 1.0 or row['ethnicity'] == 1001.0 or row['ethnicity'] == 1002.0 or row['ethnicity'] == 1003.0:\n",
    "        pdf_rename.at[index, 'white_yes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create 4 seasons of accelerometer wear using accelerometer wear start date\n",
    "def filter_accwear_month(date):\n",
    "    if date.month in [12, 1, 2]:\n",
    "        return 1\n",
    "    elif date.month in [3, 4, 5]:\n",
    "        return 2\n",
    "    elif date.month in [6, 7, 8]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4  \n",
    "\n",
    "pdf_rename['acc_wearmonth'] = pdf_rename['acc_start_date'].apply(filter_accwear_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with missing sleep survey data 96703\n"
     ]
    }
   ],
   "source": [
    "#drop -1 (\"do not know\") and -3 (\"prefer not to answer\") from sleep duration survey\n",
    "pdf_rename = pdf_rename[~(pdf_rename['sleep'] == -3)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['sleep'] == -1)]\n",
    "print('after dropping px with missing sleep survey data', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clean employment survey arrays\n",
    "pdf_rename['employ_status'].head(10)\n",
    "pdf_rename['employ_status'].dtype\n",
    "def employ_array(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return np.array(lst)\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "pdf_rename['employ_status_array'] = pdf_rename['employ_status'].apply(employ_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#continue cleaning employment covariate\n",
    "pdf_rename['employ_status_array'].head(10)\n",
    "pdf_rename['employ_status_array'].dtype\n",
    "#drop missing survey data/chose not to respond\n",
    "pdf_rename = pdf_rename[~(pdf_rename['employ_status'] == -3)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['employ_status'] == -7)]\n",
    "\n",
    "def create_employ_array_filter(arr):\n",
    "    if isinstance(arr, np.ndarray):\n",
    "        setA = set(arr).intersection({2, 3, 4, 5, 6})\n",
    "        setB = set(arr).intersection({1, 7})\n",
    "\n",
    "        if setA and setB:\n",
    "            return 2\n",
    "        elif setA:\n",
    "            return 0\n",
    "        elif setB:\n",
    "            return 1\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None \n",
    "    \n",
    "pdf_rename['employ_status_array_filter'] = pdf_rename['employ_status_array'].apply(create_employ_array_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if px did not respond/chose to say they don't want to respond, drop these patients from df\n",
    "def drop_employ_nonresponse(arr):\n",
    "    if isinstance(arr, np.ndarray):\n",
    "        return any(x in arr for x in [-3, -7])\n",
    "    else:\n",
    "        return False  \n",
    "\n",
    "for index, row in pdf_rename.iterrows():\n",
    "    if drop_employ_nonresponse(row['employ_status_array']):\n",
    "        pdf_rename.drop(index, inplace=True)\n",
    "\n",
    "pdf_rename.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with missing smoking survey data 95893\n"
     ]
    }
   ],
   "source": [
    "#for smoking status, drop anyone who answered \"-3/prefer not to answer\"\n",
    "pdf_rename['smok_stat'] = pdf_rename['smok_stat'].astype(str)\n",
    "pdf_rename = pdf_rename[~pdf_rename['smok_stat'].str.contains('-3')]\n",
    "print('after dropping px with missing smoking survey data', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with incomplete screen surveys data 94936\n"
     ]
    }
   ],
   "source": [
    "#drop -1 and -3 from tv and computer and mobile phone use; fix tv use value of -10\n",
    "pdf_rename = pdf_rename[~(pdf_rename['tv'] == -3)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['tv'] == -1)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['computer'] == -3)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['computer'] == -1)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['mobile phone'] == -3)]\n",
    "pdf_rename = pdf_rename[~(pdf_rename['mobile phone'] == -1)]\n",
    "pdf_rename['tv'] = pdf_rename['tv'].replace(-10, 0.5)\n",
    "print('after dropping px with incomplete screen surveys data', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with missing sleep survey data 80704\n"
     ]
    }
   ],
   "source": [
    "pdf_rename.dropna(subset=['computer', 'tv', 'mobile phone'], inplace=True)\n",
    "print('after dropping px with missing sleep survey data', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with incomplete alcohol survey data 80679\n"
     ]
    }
   ],
   "source": [
    "#drop alc_freq values for \"prefer not to answer\"/-3\n",
    "pdf_rename = pdf_rename[~(pdf_rename['alc_freq'] == -3)]\n",
    "print('after dropping px with incomplete alcohol survey data', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reorder alc_freq values \n",
    "#if 4\tOne to three times a month | 5\tSpecial occasions only | 6\tNever, then make seldom=1\n",
    "#if 2\tThree or four times a week | 3\tOnce or twice a week, then make sometimes=2\n",
    "#if 1\tDaily or almost daily, then make daily=3\n",
    "pdf_rename['alc_freq_filter'] = np.where(pdf_rename['alc_freq'].isin([4, 5, 6]), 1, \n",
    "                    np.where(pdf_rename['alc_freq'].isin([2, 3]), 2, \n",
    "                             np.where(pdf_rename['alc_freq'].isin([1]), 3, np.nan)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with incomplete and missing disability assistance survey data 80428\n"
     ]
    }
   ],
   "source": [
    "#fix government assistance covariate\n",
    "pdf_rename['gov_assistance'] = pdf_rename['gov_assistance'].astype(str)\n",
    "def gov_assist_filter(row):\n",
    "    if '-3' in row['gov_assistance']:\n",
    "        return None\n",
    "    elif '-1' in row['gov_assistance']:\n",
    "        return None\n",
    "    elif '-7' in row['gov_assistance']:\n",
    "        return 0\n",
    "    elif '1' in row['gov_assistance']:\n",
    "        return 1\n",
    "    elif '2' in row['gov_assistance']:\n",
    "        return 1\n",
    "    elif '3' in row['gov_assistance']:\n",
    "        return 1\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "pdf_rename['gov_assistance_filter'] = pdf_rename.apply(gov_assist_filter, axis=1)\n",
    "#drop rows with missing government assistance info\n",
    "pdf_rename.dropna(subset=['gov_assistance_filter'], inplace=True)\n",
    "print('after dropping px with incomplete and missing disability assistance survey data', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with self-reported HA or CeVD prior to baseline 78350\n"
     ]
    }
   ],
   "source": [
    "#convert sr_illness to string\n",
    "pdf_rename['sr_illness'].dtype\n",
    "pdf_rename['sr_illness'] = pdf_rename['sr_illness'].astype(str)\n",
    "#remove 1075= heart attack, 1081= stroke, 1082= tia, 1086= sah, 1282= brao/crao, 1491= brain hemorrhage, 1583= ischemic stroke\n",
    "pdf_rename = pdf_rename[~pdf_rename['sr_illness'].str.contains('1075|1081|1082|1086|1282|1491|1583')]\n",
    "print('after dropping px with self-reported HA or CeVD prior to baseline', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert dates to datetime values or analysis\n",
    "pdf_rename[\"date_i0\"] = pd.to_datetime(pdf_rename[\"date_i0\"])\n",
    "pdf_rename[\"i21_date\"] = pd.to_datetime(pdf_rename[\"i21_date\"])\n",
    "pdf_rename[\"f01_date\"] = pd.to_datetime(pdf_rename[\"f01_date\"])\n",
    "pdf_rename[\"g45_date\"] = pd.to_datetime(pdf_rename[\"g45_date\"])\n",
    "pdf_rename[\"g46_date\"] = pd.to_datetime(pdf_rename[\"g46_date\"])\n",
    "pdf_rename[\"h34_date\"] = pd.to_datetime(pdf_rename[\"h34_date\"])\n",
    "pdf_rename[\"i60_date\"] = pd.to_datetime(pdf_rename[\"i60_date\"])\n",
    "pdf_rename[\"i61_date\"] = pd.to_datetime(pdf_rename[\"i61_date\"])\n",
    "pdf_rename[\"i62_date\"] = pd.to_datetime(pdf_rename[\"i62_date\"])\n",
    "pdf_rename[\"i63_date\"] = pd.to_datetime(pdf_rename[\"i63_date\"])\n",
    "pdf_rename[\"i64_date\"] = pd.to_datetime(pdf_rename[\"i64_date\"])\n",
    "pdf_rename[\"i65_date\"] = pd.to_datetime(pdf_rename[\"i65_date\"])\n",
    "pdf_rename[\"i66_date\"] = pd.to_datetime(pdf_rename[\"i66_date\"])\n",
    "pdf_rename[\"i67_date\"] = pd.to_datetime(pdf_rename[\"i67_date\"])\n",
    "pdf_rename[\"i68_date\"] = pd.to_datetime(pdf_rename[\"i68_date\"])\n",
    "pdf_rename[\"i69_date\"] = pd.to_datetime(pdf_rename[\"i69_date\"])\n",
    "pdf_rename[\"f31_date\"] = pd.to_datetime(pdf_rename[\"f31_date\"])\n",
    "pdf_rename[\"f32_date\"] = pd.to_datetime(pdf_rename[\"f32_date\"])\n",
    "pdf_rename[\"f33_date\"] = pd.to_datetime(pdf_rename[\"f33_date\"])\n",
    "pdf_rename[\"acc_end_date\"] = pd.to_datetime(pdf_rename[\"acc_end_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with medical record HA prior to baseline 78296\n"
     ]
    }
   ],
   "source": [
    "#drop px with prior heart attack (HA) \n",
    "#convert date columns to days format\n",
    "pdf_rename['i21_time'] = (pdf_rename['date_i0'] - pdf_rename['i21_date']).dt.days\n",
    "#drop cases with a prior heart attack (I21)\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i21_time'] < 0) | (pdf_rename['i21_time'].isna())]\n",
    "print('after dropping px with medical record HA prior to baseline', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with other self-report question on HA/stroke/prefer not to answer prior to baseline 77609\n"
     ]
    }
   ],
   "source": [
    "#convert vasc_diag to string\n",
    "pdf_rename['vasc_diag'].dtype\n",
    "pdf_rename['vasc_diag'] = pdf_rename['vasc_diag'].astype(str)\n",
    "#drop px who report prior vascular diagnoses of HA, STROKE, PREFER NOT TO ANSWER\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['vasc_diag'] == '[-7]') | (pdf_rename['vasc_diag']  == '[4]') | (pdf_rename['vasc_diag']  == '[2]')]\n",
    "print('after dropping px with other self-report question on HA/stroke/prefer not to answer prior to baseline', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check number of px with TIA prior to baseline 405\n",
      "check number of px with I63 prior to baseline 172\n",
      "check number of px with I64  prior to baseline 139\n"
     ]
    }
   ],
   "source": [
    "#check cases with a prior vascular brain syndromes of CeVD (G46)\n",
    "pdf_rename['g45_time'] = (pdf_rename['acc_end_date'] - pdf_rename['g45_date']).dt.days\n",
    "pdf_rename_check_g45 = pdf_rename.loc[(pdf_rename['g45_time'] > 0)]\n",
    "print('check number of px with TIA prior to baseline', len(pdf_rename_check_g45))\n",
    "#drop cases with a prior vascular brain syndromes of CeVD (G46)\n",
    "pdf_rename['i63_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i63_date']).dt.days\n",
    "pdf_rename_check_i63 = pdf_rename.loc[(pdf_rename['i63_time'] > 0)]\n",
    "print('check number of px with I63 prior to baseline', len(pdf_rename_check_i63))\n",
    "#drop cases with a prior vascular brain syndromes of CeVD (G46)\n",
    "pdf_rename['i64_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i64_date']).dt.days\n",
    "pdf_rename_check_i64 = pdf_rename.loc[(pdf_rename['i64_time'] > 0)]\n",
    "print('check number of px with I64  prior to baseline', len(pdf_rename_check_i64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping px with CeVD diagnoses in medical records prior to baseline 76505\n"
     ]
    }
   ],
   "source": [
    "#drop prior CevD px who have recorded diagnosis in medical records\n",
    "#drop cases with a prior vascular dementia (F01)\n",
    "pdf_rename['f01_time'] = (pdf_rename['acc_end_date'] - pdf_rename['f01_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['f01_time'] < 0) | (pdf_rename['f01_time'].isna())]\n",
    "\n",
    "#drop cases with a prior TIA (G45)\n",
    "pdf_rename['g45_time'] = (pdf_rename['acc_end_date'] - pdf_rename['g45_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['g45_time'] < 0) | (pdf_rename['g45_time'].isna())]\n",
    "\n",
    "#drop cases with a prior vascular brain syndromes of CeVD (G46)\n",
    "pdf_rename['g46_time'] = (pdf_rename['acc_end_date'] - pdf_rename['g46_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['g46_time'] < 0) | (pdf_rename['g46_time'].isna())]\n",
    "\n",
    "#drop cases with a prior RAO (H34)\n",
    "pdf_rename['h34_time'] = (pdf_rename['acc_end_date'] - pdf_rename['h34_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['h34_time'] < 0) | (pdf_rename['h34_time'].isna())]\n",
    "\n",
    "#drop cases with a prior Nontraumatic subarachnoid hemorrhage (I60)\n",
    "pdf_rename['i60_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i60_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i60_time'] < 0) | (pdf_rename['i60_time'].isna())]\n",
    "\n",
    "#drop cases with a prior Nontraumatic intracerebral hemorrhage (I61)\n",
    "pdf_rename['i61_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i61_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i61_time'] < 0) | (pdf_rename['i61_time'].isna())]\n",
    "\n",
    "#drop cases with a prior Other and unspecified nontraumatic intracranial hemorrhage (I62)\n",
    "pdf_rename['i62_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i62_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i62_time'] < 0) | (pdf_rename['i62_time'].isna())]\n",
    "\n",
    "#drop cases with a prior intracerebral infarction (I63)\n",
    "pdf_rename['i63_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i63_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i63_time'] < 0) | (pdf_rename['i63_time'].isna())]\n",
    "\n",
    "#drop cases with a prior unspecified stroke (I64)\n",
    "pdf_rename['i64_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i64_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i64_time'] < 0) | (pdf_rename['i64_time'].isna())]\n",
    "\n",
    "#drop cases with a prior occlusion/stenosis precerebral arteries (I65)\n",
    "pdf_rename['i65_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i65_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i65_time'] < 0) | (pdf_rename['i65_time'].isna())]\n",
    "\n",
    "#drop cases with a prior occlusion/stenosis cerebral arteries (I66)\n",
    "pdf_rename['i66_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i66_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i66_time'] < 0) | (pdf_rename['i66_time'].isna())]\n",
    "\n",
    "#drop cases with a prior Other cerebrovascular diseases (I67)\n",
    "pdf_rename['i67_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i67_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i67_time'] < 0) | (pdf_rename['i67_time'].isna())]\n",
    "\n",
    "#drop cases with a prior Cerebrovascular disorders in diseases classified elsewhere (I68)\n",
    "pdf_rename['i68_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i68_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i68_time'] < 0) | (pdf_rename['i68_time'].isna())]\n",
    "\n",
    "#drop cases with a prior Sequelae of cerebrovascular disease (I69)\n",
    "pdf_rename['i69_time'] = (pdf_rename['acc_end_date'] - pdf_rename['i69_date']).dt.days\n",
    "pdf_rename = pdf_rename.loc[(pdf_rename['i69_time'] < 0) | (pdf_rename['i69_time'].isna())]\n",
    "\n",
    "print('after dropping px with CeVD diagnoses in medical records prior to baseline', len(pdf_rename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of px with depression diagnosis (F31, F32, F33): 6737\n"
     ]
    }
   ],
   "source": [
    "#prep depression cases in \"days\" format\n",
    "pdf_rename['f31_time'] = (pdf_rename['acc_end_date'] - pdf_rename['f31_date']).dt.days\n",
    "pdf_rename['f32_time'] = (pdf_rename['acc_end_date'] - pdf_rename['f32_date']).dt.days\n",
    "pdf_rename['f33_time'] = (pdf_rename['acc_end_date'] - pdf_rename['f33_date']).dt.days\n",
    "# check for diagnosed depression; if yes, return 1\n",
    "def check_for_dep_diag(row):\n",
    "    if row['f31_time'] > 0 or row['f32_time'] > 0 or row['f33_time'] > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "pdf_rename['dep_diag_yes'] = pdf_rename.apply(check_for_dep_diag, axis=1)\n",
    "check_dep_diag = pdf_rename['dep_diag_yes'].sum()\n",
    "print(\"Number of px with depression diagnosis (F31, F32, F33):\", check_dep_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median depression duration: 4163.0\n"
     ]
    }
   ],
   "source": [
    "#pull earliest depression diagnosis per row; make depression duration variable\n",
    "pdf_rename['dep_dur'] = pdf_rename[['f31_time', 'f32_time', 'f33_time']].max(axis=1)\n",
    "print(\"median depression duration:\", pdf_rename['dep_dur'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check depression duration variable with histogram\n",
    "plt.hist(pdf_rename['dep_dur'], bins=20, color='blue', alpha=0.7) \n",
    "plt.xlabel('Depression Duration (Days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fill empty rows in white_yes with 0; some 0 variables did not convert correctly and need manual imput\n",
    "pdf_rename['white_yes'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate sum values of time spent in exercise for the 4 divided times per day (0:00-5:59; 6:00-11:59,etc)\n",
    "for index, row in pdf_rename.iterrows():\n",
    "    pdf_rename.at[index, 'pa_time_a'] = row['pa_time_1'] + row['pa_time_2'] + row['pa_time_3'] + row['pa_time_4'] + row['pa_time_5'] + row['pa_time_6']\n",
    "\n",
    "for index, row in pdf_rename.iterrows():\n",
    "    pdf_rename.at[index, 'pa_time_b'] = row['pa_time_7'] + row['pa_time_8'] + row['pa_time_9'] + row['pa_time_10'] + row['pa_time_11'] + row['pa_time_12']\n",
    "\n",
    "for index, row in pdf_rename.iterrows():\n",
    "    pdf_rename.at[index, 'pa_time_c'] = row['pa_time_13'] + row['pa_time_14'] + row['pa_time_15'] + row['pa_time_16'] + row['pa_time_17'] + row['pa_time_18']\n",
    "\n",
    "for index, row in pdf_rename.iterrows():\n",
    "    pdf_rename.at[index, 'pa_time_d'] = row['pa_time_19'] + row['pa_time_20'] + row['pa_time_21'] + row['pa_time_22'] + row['pa_time_23'] + row['pa_time_24']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.96, 0.97, 0.95, 0.96, 1, 1, 0.95, 0.57, 0.1...\n",
       "1    [0.98, 1, 1, 1, 1, 1, 1, 0.44, 0.02, 0.14, 0, ...\n",
       "2    [1, 0.99, 1, 1, 1, 0.85, 0.34, 0.47, 0.1, 0, 0...\n",
       "3    [0.47, 0.5, 0.45, 0.4, 0.51, 0.44, 0.4, 0.43, ...\n",
       "4    [0.73, 1, 1, 1, 1, 0.98, 0.88, 0.84, 0.66, 0.2...\n",
       "Name: pa_sleep_day_hour_array, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check pa types are in object non-array format\n",
    "pdf_rename['pa_sleep_day_hour'].head(5)\n",
    "#convert pa types to array for iterating\n",
    "def convert_patypes_array(x):\n",
    "    if pd.notna(x):\n",
    "        return np.array(x.split(','))\n",
    "    else:\n",
    "        return np.array([])\n",
    "\n",
    "pdf_rename['pa_sleep_day_hour_array'] = pdf_rename['pa_sleep_day_hour'].apply(convert_patypes_array)\n",
    "pdf_rename['pa_sed_day_hour_array'] = pdf_rename['pa_sed_day_hour'].apply(convert_patypes_array)\n",
    "pdf_rename['pa_light_day_hour_array'] = pdf_rename['pa_light_day_hour'].apply(convert_patypes_array)\n",
    "pdf_rename['pa_mv_day_hour_array'] = pdf_rename['pa_mv_day_hour'].apply(convert_patypes_array)\n",
    "#check array conversion successful\n",
    "pdf_rename['pa_sleep_day_hour_array'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert all values in arrays to numeric\n",
    "def array_to_numeric(arr):\n",
    "    return [pd.to_numeric(val, errors='coerce') for val in arr]\n",
    "\n",
    "pdf_rename['pa_sleep_day_hour_array'] = pdf_rename['pa_sleep_day_hour_array'].apply(array_to_numeric)\n",
    "pdf_rename['pa_sed_day_hour_array'] = pdf_rename['pa_sed_day_hour_array'].apply(array_to_numeric)\n",
    "pdf_rename['pa_light_day_hour_array'] = pdf_rename['pa_light_day_hour_array'].apply(array_to_numeric)\n",
    "pdf_rename['pa_mv_day_hour_array'] = pdf_rename['pa_mv_day_hour_array'].apply(array_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [57.599999999999994, 58.199999999999996, 57.0,...\n",
       "1    [58.8, 60, 60, 60, 60, 60, 60, 26.4, 1.2, 8.4,...\n",
       "2    [60, 59.4, 60, 60, 60, 51.0, 20.40000000000000...\n",
       "3    [28.2, 30.0, 27.0, 24.0, 30.6, 26.4, 24.0, 25....\n",
       "4    [43.8, 60, 60, 60, 60, 58.8, 52.8, 50.4, 39.6,...\n",
       "Name: pa_sleep_day_hour_array_clean, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert values in arrays from % per hour per day to total minutes per hour per day\n",
    "def array_perc_to_min(arr):\n",
    "    return [x * 60 for x in arr]\n",
    "pdf_rename['pa_sleep_day_hour_array_clean'] = pdf_rename['pa_sleep_day_hour_array'].apply(array_perc_to_min)\n",
    "pdf_rename['pa_sed_day_hour_array_clean'] = pdf_rename['pa_sed_day_hour_array'].apply(array_perc_to_min)\n",
    "pdf_rename['pa_light_day_hour_array_clean'] = pdf_rename['pa_light_day_hour_array'].apply(array_perc_to_min)\n",
    "pdf_rename['pa_mv_day_hour_array_clean'] = pdf_rename['pa_mv_day_hour_array'].apply(array_perc_to_min)\n",
    "#check conversion to min is successful\n",
    "pdf_rename['pa_sleep_day_hour_array_clean'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2564/997299406.py:10: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pdf_rename[['pa_sleep_day_1', 'pa_sleep_day_2', 'pa_sleep_day_3', 'pa_sleep_day_4']] = pdf_rename['pa_sleep_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
      "/tmp/ipykernel_2564/997299406.py:11: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pdf_rename[['pa_sed_day_1', 'pa_sed_day_2', 'pa_sed_day_3', 'pa_sed_day_4']] = pdf_rename['pa_sed_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
      "/tmp/ipykernel_2564/997299406.py:12: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pdf_rename[['pa_light_day_1', 'pa_light_day_2', 'pa_light_day_3', 'pa_light_day_4']] = pdf_rename['pa_light_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
      "/tmp/ipykernel_2564/997299406.py:13: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pdf_rename[['pa_mv_day_1', 'pa_mv_day_2', 'pa_mv_day_3', 'pa_mv_day_4']] = pdf_rename['pa_mv_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3    10.8\n",
       "4     0.0\n",
       "Name: pa_mv_day_1, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create variables stratified by time of day (4 groups) consisting of 6 hours each\n",
    "def create_pa_timeepochs(arr):\n",
    "    sums = []\n",
    "    for i in range(0, len(arr), 6):\n",
    "        block = arr[i:i+6]\n",
    "        sum_block = sum(block)\n",
    "        sums.append(sum_block)\n",
    "    return sums\n",
    "\n",
    "pdf_rename[['pa_sleep_day_1', 'pa_sleep_day_2', 'pa_sleep_day_3', 'pa_sleep_day_4']] = pdf_rename['pa_sleep_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
    "pdf_rename[['pa_sed_day_1', 'pa_sed_day_2', 'pa_sed_day_3', 'pa_sed_day_4']] = pdf_rename['pa_sed_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
    "pdf_rename[['pa_light_day_1', 'pa_light_day_2', 'pa_light_day_3', 'pa_light_day_4']] = pdf_rename['pa_light_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
    "pdf_rename[['pa_mv_day_1', 'pa_mv_day_2', 'pa_mv_day_3', 'pa_mv_day_4']] = pdf_rename['pa_mv_day_hour_array_clean'].apply(create_pa_timeepochs).apply(pd.Series)\n",
    "#check conversion successful\n",
    "pdf_rename['pa_mv_day_1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    105.6\n",
       "1     96.0\n",
       "2     54.6\n",
       "3    144.0\n",
       "4    166.2\n",
       "Name: pa_sleep_day_2, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check creation successful\n",
    "pdf_rename['pa_sleep_day_2'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    229.8\n",
       "1    162.0\n",
       "2    133.8\n",
       "3    165.0\n",
       "4    127.2\n",
       "Name: pa_sed_day_3, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check creation successful\n",
    "pdf_rename['pa_sed_day_3'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    109.2\n",
       "1      9.0\n",
       "2    199.2\n",
       "3     70.2\n",
       "4     75.6\n",
       "Name: pa_sleep_day_4, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check creation successful\n",
    "pdf_rename['pa_sleep_day_4'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create comorbidity covariate in multiple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert comorbidity diagnosis dates to datetime format\n",
    "pdf_rename[\"i10_date\"] = pd.to_datetime(pdf_rename[\"i10_date\"])\n",
    "pdf_rename[\"i15_date\"] = pd.to_datetime(pdf_rename[\"i15_date\"])\n",
    "pdf_rename[\"e78_date\"] = pd.to_datetime(pdf_rename[\"e78_date\"])\n",
    "pdf_rename[\"e10_date\"] = pd.to_datetime(pdf_rename[\"e10_date\"])\n",
    "pdf_rename[\"e11_date\"] = pd.to_datetime(pdf_rename[\"e11_date\"])\n",
    "pdf_rename[\"i50_date\"] = pd.to_datetime(pdf_rename[\"i50_date\"])\n",
    "pdf_rename[\"i25_date\"] = pd.to_datetime(pdf_rename[\"i25_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create hypertension category\n",
    "#prep htn cases\n",
    "pdf_rename['i10_time'] = (pdf_rename['date_i0'] - pdf_rename['i10_date']).dt.days\n",
    "pdf_rename['i15_time'] = (pdf_rename['date_i0'] - pdf_rename['i15_date']).dt.days\n",
    "\n",
    "# check for htn; if yes, return 1\n",
    "def check_htn_criteria(row):\n",
    "    if row['i10_time'] > 0 or row['i15_time'] > 0 or '1065' in row['sr_illness'] or '1072' in row['sr_illness']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "pdf_rename['htn_yes'] = pdf_rename.apply(check_htn_criteria, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create heart failure category\n",
    "#prep  cases\n",
    "pdf_rename['i50_time'] = (pdf_rename['date_i0'] - pdf_rename['i50_date']).dt.days\n",
    "\n",
    "# check for htn; if yes, return 1\n",
    "def check_htn_criteria(row):\n",
    "    if row['i50_time'] > 0  or '1076' in row['sr_illness']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "pdf_rename['hf_yes'] = pdf_rename.apply(check_htn_criteria, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create cad category\n",
    "#prep  cases\n",
    "pdf_rename['i25_time'] = (pdf_rename['date_i0'] - pdf_rename['i25_date']).dt.days\n",
    "\n",
    "# check for htn; if yes, return 1\n",
    "def check_htn_criteria(row):\n",
    "    if row['i25_time'] > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "pdf_rename['cad_yes'] = pdf_rename.apply(check_htn_criteria, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create cancer covariate\n",
    "pdf_rename['cancer_yes'] = pdf_rename['p134_i0'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create hyperlipidemia category\n",
    "#prep hchol cases\n",
    "pdf_rename['e78_time'] = (pdf_rename['date_i0'] - pdf_rename['e78_date']).dt.days\n",
    "def check_hchol_criteria(row):\n",
    "    if row['e78_time'] > 0 or '1473' in row['sr_illness']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "pdf_rename['hchol_yes'] = pdf_rename.apply(check_hchol_criteria, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create diabetes category\n",
    "#prep diabetes cases\n",
    "pdf_rename['e10_date'] = pd.to_datetime(pdf_rename['e10_date'])\n",
    "pdf_rename['e11_date'] = pd.to_datetime(pdf_rename['e11_date'])\n",
    "pdf_rename['date_i0'] = pd.to_datetime(pdf_rename['date_i0'])\n",
    "pdf_rename['e10_time'] = (pdf_rename['date_i0'] - pdf_rename['e10_date']).dt.days\n",
    "pdf_rename['e11_time'] = (pdf_rename['date_i0'] - pdf_rename['e11_date']).dt.days\n",
    "\n",
    "def check_diab_criteria(row):\n",
    "    if row['e10_time'] > 0 or row['e11_time'] > 0 or '1222' in row['sr_illness'] or '1223' in row['sr_illness']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "pdf_rename['diab_yes'] = pdf_rename.apply(check_diab_criteria, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create comorbidity covariate for analysis and filter covariate for baseline characteristics table considering set of comorbidities created above\n",
    "pdf_rename['comorb_sum'] = pdf_rename[['htn_yes', 'hf_yes', 'cad_yes', 'cancer_yes', 'hchol_yes', 'diab_yes']].sum(axis=1)\n",
    "pdf_rename['comorb_sum_filter'] = pdf_rename['comorb_sum'].apply(lambda x: 0 if x == 0 else (1 if x == 1 else 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prep clean cevd endpoint variable as first day in px chart with CeVD diagnosis after accelerometer study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if assessment date - event date < 0, then copy absolute value to corresponding column\n",
    "pdf_rename.loc[pdf_rename['f01_time'] < 0, 'f01_t2e'] = abs(pdf_rename['f01_time'])\n",
    "pdf_rename.loc[pdf_rename['g45_time'] < 0, 'g45_t2e'] = abs(pdf_rename['g45_time'])\n",
    "pdf_rename.loc[pdf_rename['g46_time'] < 0, 'g46_t2e'] = abs(pdf_rename['g46_time'])\n",
    "pdf_rename.loc[pdf_rename['h34_time'] < 0, 'h34_t2e'] = abs(pdf_rename['h34_time'])\n",
    "pdf_rename.loc[pdf_rename['i60_time'] < 0, 'i60_t2e'] = abs(pdf_rename['i60_time'])\n",
    "pdf_rename.loc[pdf_rename['i61_time'] < 0, 'i61_t2e'] = abs(pdf_rename['i61_time'])\n",
    "pdf_rename.loc[pdf_rename['i62_time'] < 0, 'i62_t2e'] = abs(pdf_rename['i62_time'])\n",
    "pdf_rename.loc[pdf_rename['i63_time'] < 0, 'i63_t2e'] = abs(pdf_rename['i63_time'])\n",
    "pdf_rename.loc[pdf_rename['i64_time'] < 0, 'i64_t2e'] = abs(pdf_rename['i64_time'])\n",
    "pdf_rename.loc[pdf_rename['i65_time'] < 0, 'i65_t2e'] = abs(pdf_rename['i65_time'])\n",
    "pdf_rename.loc[pdf_rename['i66_time'] < 0, 'i66_t2e'] = abs(pdf_rename['i66_time'])\n",
    "pdf_rename.loc[pdf_rename['i67_time'] < 0, 'i67_t2e'] = abs(pdf_rename['i67_time'])\n",
    "pdf_rename.loc[pdf_rename['i68_time'] < 0, 'i68_t2e'] = abs(pdf_rename['i68_time'])\n",
    "pdf_rename.loc[pdf_rename['i69_time'] < 0, 'i69_t2e'] = abs(pdf_rename['i69_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if there is a time-to-event in XXX_t2e, then place 1 in outcome column for each CeVD\n",
    "pdf_rename.loc[pdf_rename['f01_t2e'].notna(), 'f01_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['g45_t2e'].notna(), 'g45_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['g46_t2e'].notna(), 'g46_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['h34_t2e'].notna(), 'h34_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i60_t2e'].notna(), 'i60_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i61_t2e'].notna(), 'i61_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i62_t2e'].notna(), 'i62_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i63_t2e'].notna(), 'i63_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i64_t2e'].notna(), 'i64_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i65_t2e'].notna(), 'i65_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i66_t2e'].notna(), 'i66_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i67_t2e'].notna(), 'i67_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i68_t2e'].notna(), 'i68_event'] = 1\n",
    "pdf_rename.loc[pdf_rename['i69_t2e'].notna(), 'i69_event'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CeVD events (total) 2163.0\n"
     ]
    }
   ],
   "source": [
    "#create composite cevd outcome value\n",
    "pdf_rename.loc[(pdf_rename['f01_event'].notna()) | (pdf_rename['g45_event'].notna()) | (pdf_rename['g46_event'].notna()) | (pdf_rename['h34_event'].notna()) | (pdf_rename['i60_event'].notna()) | (pdf_rename['i61_event'].notna()) | (pdf_rename['i62_event'].notna()) | (pdf_rename['i63_event'].notna()) | (pdf_rename['i64_event'].notna()) | (pdf_rename['i65_event'].notna()) | (pdf_rename['i66_event'].notna()) | (pdf_rename['i67_event'].notna()) | (pdf_rename['i68_event'].notna()) | (pdf_rename['i69_event'].notna()), 'cevd_event'] = 1\n",
    "pdf_rename['cevd_event'] = pdf_rename['cevd_event'].fillna(0)\n",
    "\n",
    "#check number of future cevd_events \n",
    "sum_cevdevents = pdf_rename['cevd_event'].sum()\n",
    "print('Number of CeVD events (total)', sum_cevdevents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create cevd time-to-event value for earliest cevd event\n",
    "pdf_rename['cevd_t2e'] = pdf_rename[['f01_t2e', 'g45_t2e', 'g46_t2e', 'h34_t2e', 'i60_t2e', 'i61_t2e', 'i62_t2e', 'i63_t2e', 'i64_t2e', 'i65_t2e', 'i66_t2e', 'i67_t2e', 'i68_t2e', 'i69_t2e']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert all t2e columns to numeric for filtering\n",
    "def convert_t2e_to_numeric(df):\n",
    "    df['f01_t2e'] = pd.to_numeric(df['f01_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['g45_t2e'] = pd.to_numeric(df['g45_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['g46_t2e'] = pd.to_numeric(df['g46_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['h34_t2e'] = pd.to_numeric(df['h34_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i60_t2e'] = pd.to_numeric(df['i60_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i61_t2e'] = pd.to_numeric(df['i61_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i62_t2e'] = pd.to_numeric(df['i62_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i63_t2e'] = pd.to_numeric(df['i63_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i64_t2e'] = pd.to_numeric(df['i64_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i65_t2e'] = pd.to_numeric(df['i65_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i66_t2e'] = pd.to_numeric(df['i66_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i67_t2e'] = pd.to_numeric(df['i67_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i68_t2e'] = pd.to_numeric(df['i68_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['i69_t2e'] = pd.to_numeric(df['i69_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    df['cevd_t2e'] = pd.to_numeric(df['cevd_t2e'], errors='coerce').astype(pd.Int64Dtype())\n",
    "    return df\n",
    "\n",
    "pdf_rename = convert_t2e_to_numeric(pdf_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#clean all cevd types to only have t2e for the initial CeVD diagnosis after accelerometer study commencement\n",
    "def check_cevd_types(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['f01_t2e']):\n",
    "            if row['f01_t2e'] != row['cevd_t2e']:\n",
    "                df.at[index, 'f01_t2e'] = None\n",
    "        if pd.notna(row['g45_t2e']):\n",
    "            if row['g45_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'g45_t2e'] = None\n",
    "        if pd.notna(row['g46_t2e']):\n",
    "            if row['g46_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'g46_t2e'] = None\n",
    "        if pd.notna(row['h34_t2e']):\n",
    "            if row['h34_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'h34_t2e'] = None\n",
    "        if pd.notna(row['i60_t2e']):\n",
    "            if row['i60_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i60_t2e'] = None\n",
    "        if pd.notna(row['i61_t2e']):\n",
    "            if row['i61_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i61_t2e'] = None\n",
    "        if pd.notna(row['i62_t2e']):\n",
    "            if row['i62_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i62_t2e'] = None\n",
    "        if pd.notna(row['i63_t2e']):\n",
    "            if row['i63_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i63_t2e'] = None\n",
    "        if pd.notna(row['i64_t2e']):\n",
    "            if row['i64_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i64_t2e'] = None\n",
    "        if pd.notna(row['i65_t2e']):\n",
    "            if row['i65_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i65_t2e'] = None\n",
    "        if pd.notna(row['i66_t2e']):\n",
    "            if row['i66_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i66_t2e'] = None\n",
    "        if pd.notna(row['i67_t2e']):\n",
    "            if row['i67_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i67_t2e'] = None\n",
    "        if pd.notna(row['i68_t2e']):\n",
    "            if row['i68_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i68_t2e'] = None\n",
    "        if pd.notna(row['i69_t2e']):\n",
    "            if row['i69_t2e'] != row['cevd_t2e']:\n",
    "                 df.at[index, 'i69_t2e'] = None\n",
    "    return df\n",
    "\n",
    "cevd_df_first = check_cevd_types(pdf_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows with missing BMI data: 142\n"
     ]
    }
   ],
   "source": [
    "#get the number of missing BMI values for imputation\n",
    "missing_bmi = cevd_df_first['bmi'].isna().sum()\n",
    "print('number of rows with missing BMI data:', missing_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#USE MUTIPLE CHAIN IMPUTATION FOR MISSING BMI DATA\n",
    "cols_to_impute = ['bmi']\n",
    "# create an instance of the IterativeImputer class with MICE algorithm\n",
    "imputer = IterativeImputer(max_iter=10, sample_posterior=True)\n",
    "# impute the selected columns using multiple chains\n",
    "cevd_df_first[cols_to_impute] = imputer.fit_transform(cevd_df_first[cols_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a value with the day of intitial CeVD diagnosis after accelerometer study commencement\n",
    "def find_firstday_cevd(row):\n",
    "    dates = [row['f01_date'], row['g45_date'], row['g46_date'], row['h34_date'], row['i60_date'], row['i61_date'], row['i62_date'], row['i63_date'], row['i64_date'], row['i65_date'], row['i66_date'], row['i67_date'], row['i68_date'], row['i69_date']]\n",
    "    non_empty_dates = [date for date in dates if not pd.isnull(date)]\n",
    "    return min(non_empty_dates) if non_empty_dates else pd.NaT\n",
    "\n",
    "cevd_df_first['cevd_day'] = cevd_df_first.apply(find_firstday_cevd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirming the df length is 76,505 (complete) after wrangling 76505\n"
     ]
    }
   ],
   "source": [
    "print('confirming the df length is 76,505 (complete) after wrangling', len(cevd_df_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in cohort with a future CeVD: 2163\n"
     ]
    }
   ],
   "source": [
    "#check the number of px with a future CeVD in cohort\n",
    "total_futurecevd = cevd_df_first[cevd_df_first['cevd_event']==1]\n",
    "print('Number of patients in cohort with a future CeVD:', len(total_futurecevd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create screen use covariate in multiple steps\n",
    "screen_column = ['computer', 'tv', 'mobile phone']\n",
    "cevd_df_first['tv'] = cevd_df_first['tv'].replace(-10, 0.5)\n",
    "cevd_df_first['computer'] = cevd_df_first['computer'].replace(-10, 0.5)\n",
    "cevd_df_first[screen_column] = cevd_df_first[screen_column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reorder mobile phone use per week values \n",
    "#convert to hours or percentage of hours tied to \n",
    "cevd_df_first['mobile phone_filter'] = np.where(cevd_df_first['mobile phone'].isin([5]), 6, \n",
    "                    np.where(cevd_df_first['mobile phone'].isin([4]), 4,\n",
    "                    np.where(cevd_df_first['mobile phone'].isin([3]), 2,\n",
    "                    np.where(cevd_df_first['mobile phone'].isin([2]), 0.742, \n",
    "                    np.where(cevd_df_first['mobile phone'].isin([1]), 0.2, \n",
    "                             np.where(cevd_df_first['mobile phone'].isin([0]), 0.083, np.nan))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.000000\n",
       "1    0.000000\n",
       "2    7.142857\n",
       "3    3.142857\n",
       "Name: full_screen_time, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#screentime per day\n",
    "cevd_df_first['full_screen_time'] = (cevd_df_first['computer']*1) + (cevd_df_first['tv']*1) + (cevd_df_first['mobile phone']/7)\n",
    "cevd_df_first['full_screen_time'].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of non-future CeVD px: 74342\n"
     ]
    }
   ],
   "source": [
    "total_futurecevd = cevd_df_first[cevd_df_first['cevd_event']==0]\n",
    "print('number of non-future CeVD px:', len(total_futurecevd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#screen time per day filter; greater than 2 = 0\n",
    "def assign_value(x):\n",
    "    if x <= 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "cevd_df_first['full_screen_time_filter'] = cevd_df_first['full_screen_time'].apply(assign_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get baseline characteristics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76505"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cevd_df_first_onlycevd = cevd_df_first\n",
    "len(cevd_df_first_onlycevd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2163"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cevd_df_first_onlycevd[cevd_df_first_onlycevd['cevd_event'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Age with exp cohort: 60.562644475265834\n",
      "Standard Deviation of Age with exp cohort: 6.533209183525972\n",
      "P-value for tdi:\n",
      "Mean Age with control cohort: 55.169433160259345\n",
      "Standard Deviation of Age with control cohort: 7.784338581110335\n",
      "P-value for tdi:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=5853015025.0, pvalue=0.0)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = cevd_df_first_onlycevd[cevd_df_first_onlycevd['cevd_event'] == 1]\n",
    "mean_age = subset['age_i0'].mean()\n",
    "std_dev_age = subset['age_i0'].std()\n",
    "\n",
    "print(\"Mean Age with exp cohort:\", mean_age)\n",
    "print(\"Standard Deviation of Age with exp cohort:\", std_dev_age)\n",
    "print('P-value for tdi:')\n",
    "stats.mannwhitneyu(x=cevd_df_first_onlycevd['age_i0'], y=cevd_df_first_onlycevd['dep_diag_yes'], alternative = 'two-sided')\n",
    "subset = cevd_df_first_onlycevd[cevd_df_first_onlycevd['cevd_event'] == 0]\n",
    "mean_age = subset['age_i0'].mean()\n",
    "std_dev_age = subset['age_i0'].std()\n",
    "\n",
    "print(\"Mean Age with control cohort:\", mean_age)\n",
    "print(\"Standard Deviation of Age with control cohort:\", std_dev_age)\n",
    "print('P-value for tdi:')\n",
    "stats.mannwhitneyu(x=cevd_df_first_onlycevd['age_i0'], y=cevd_df_first_onlycevd['cevd_event'], alternative = 'two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent male: 53.07443365695793\n",
      "exp Cohort Total male: 1148\n",
      "Control Cohort Percent male: 42.313900621452206\n",
      "Control Cohort Total male: 31457\n",
      "% of men in total 76,505 cohort 42.618129534017385\n",
      "MALE - Chi-square test statistic: 99.0779667583258\n",
      "MALE - P-value: 2.4275405775932333e-23\n"
     ]
    }
   ],
   "source": [
    "#get male/female data\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'male'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'male'].sum()\n",
    "print('exp Cohort Percent male:', percent_male_d)\n",
    "print('exp Cohort Total male:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'male'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'male'].sum()\n",
    "print('Control Cohort Percent male:', percent_male_c)\n",
    "print('Control Cohort Total male:', male_sum_c)\n",
    "perc_men_total = ((male_sum_d+male_sum_c)/76505)*100\n",
    "print('% of men in total 76,505 cohort', perc_men_total)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['male'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for male data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('MALE - Chi-square test statistic:', chi2_stat)\n",
    "print('MALE - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent white: 96.9486823855756\n",
      "exp Cohort Total white: 2097.0\n",
      "Control Cohort Percent white: 96.47305695300099\n",
      "Control Cohort Total white: 71720.0\n",
      "% of white in total 76505 cohort 96.48650415005555\n",
      "white - Chi-square test statistic: 1.2657798165183423\n",
      "white - P-value: 0.26055987895621857\n"
     ]
    }
   ],
   "source": [
    "#get white/ethnicity data\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'white_yes'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'white_yes'].sum()\n",
    "print('exp Cohort Percent white:', percent_male_d)\n",
    "print('exp Cohort Total white:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'white_yes'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'white_yes'].sum()\n",
    "print('Control Cohort Percent white:', percent_male_c)\n",
    "print('Control Cohort Total white:', male_sum_c)\n",
    "perc_men_total = ((male_sum_d+male_sum_c)/76505)*100\n",
    "print('% of white in total 76505 cohort', perc_men_total)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['white_yes'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for male data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('white - Chi-square test statistic:', chi2_stat)\n",
    "print('white - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Percentages of smoke\n",
      "0    47.434119\n",
      "1    44.290337\n",
      "2     8.275543\n",
      "Name: smok_stat, dtype: Float64\n",
      "CONTROL Percentages of smoke\n",
      "0    56.814452\n",
      "1    36.108794\n",
      "2     7.076753\n",
      "Name: smok_stat, dtype: Float64\n",
      "smoke - Chi-square test statistic: 75.66819572483115\n",
      "smoke - P-value: 3.705613079037276e-17\n"
     ]
    }
   ],
   "source": [
    "#get smoking data\n",
    "cevd_df_first_onlycevd['smok_stat'] = pd.to_numeric(cevd_df_first_onlycevd['smok_stat'], errors='coerce').astype(pd.Int64Dtype())\n",
    "cevd_df_first_onlycevd['smok_filter'] = cevd_df_first_onlycevd['smok_stat'].apply(lambda x: 1 if (x > 0) else 0)\n",
    "perc_alc_freq_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'smok_stat'].value_counts(normalize=True)\n",
    "print('exp Percentages of smoke')\n",
    "print(perc_alc_freq_d * 100)\n",
    "perc_alc_freq_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'smok_stat'].value_counts(normalize=True)\n",
    "# print the value counts as percentages\n",
    "print('CONTROL Percentages of smoke')\n",
    "print(perc_alc_freq_c * 100)\n",
    "\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['smok_stat'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('smoke - Chi-square test statistic:', chi2_stat)\n",
    "print('smoke - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent bmi: 43.45815996301433\n",
      "exp Cohort Total bmi: 940\n",
      "Control Cohort Percent bmi: 49.0530252078233\n",
      "Control Cohort Total bmi: 36467\n",
      "bmi - Chi-square test statistic: 26.10666658931236\n",
      "bmi - P-value: 3.2306664090705215e-07\n"
     ]
    }
   ],
   "source": [
    "#get bmi data\n",
    "cevd_df_first_onlycevd['bmi_filter'] = cevd_df_first_onlycevd['bmi'].apply(lambda x: 1 if (x > 18.4 and x < 26) else 0)\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'bmi_filter'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'bmi_filter'].sum()\n",
    "print('exp Cohort Percent bmi:', percent_male_d)\n",
    "print('exp Cohort Total bmi:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'bmi_filter'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'bmi_filter'].sum()\n",
    "print('Control Cohort Percent bmi:', percent_male_c)\n",
    "print('Control Cohort Total bmi:', male_sum_c)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['bmi_filter'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for bmi data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('bmi - Chi-square test statistic:', chi2_stat)\n",
    "print('bmi - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent disability $: 5.224225612575127\n",
      "exp Cohort Total disability $: 113.0\n",
      "Control Cohort Percent disability $: 2.395684808049286\n",
      "Control Cohort Total disability $: 1781.0\n",
      "disability $ - Chi-square test statistic: 68.48362446190052\n",
      "disability $ - P-value: 1.2793558883069255e-16\n"
     ]
    }
   ],
   "source": [
    "#get disability assistance status data\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'gov_assistance_filter'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'gov_assistance_filter'].sum()\n",
    "print('exp Cohort Percent disability $:', percent_male_d)\n",
    "print('exp Cohort Total disability $:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'gov_assistance_filter'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'gov_assistance_filter'].sum()\n",
    "print('Control Cohort Percent disability $:', percent_male_c)\n",
    "print('Control Cohort Total disability $:', male_sum_c)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['gov_assistance_filter'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for male data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('disability $ - Chi-square test statistic:', chi2_stat)\n",
    "print('disability $ - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent screen: 13.407304669440592\n",
      "exp Cohort Total screen: 290\n",
      "Control Cohort Percent screen: 17.47733448118157\n",
      "Control Cohort Total screen: 12993\n",
      "screen - Chi-square test statistic: 23.98389491325269\n",
      "screen - P-value: 9.714490196618309e-07\n"
     ]
    }
   ],
   "source": [
    "#get screen use data\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'full_screen_time_filter'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'full_screen_time_filter'].sum()\n",
    "print('exp Cohort Percent screen:', percent_male_d)\n",
    "print('exp Cohort Total screen:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'full_screen_time_filter'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'full_screen_time_filter'].sum()\n",
    "print('Control Cohort Percent screen:', percent_male_c)\n",
    "print('Control Cohort Total screen:', male_sum_c)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['full_screen_time_filter'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for male data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('screen - Chi-square test statistic:', chi2_stat)\n",
    "print('screen - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Percentages of alc freq\n",
      "2.0    44.983819\n",
      "3.0    29.311142\n",
      "1.0    25.705039\n",
      "Name: alc_freq_filter, dtype: float64\n",
      "econtrol Percentages of alc freq\n",
      "2.0    52.606871\n",
      "1.0    24.685911\n",
      "3.0    22.707218\n",
      "Name: alc_freq_filter, dtype: float64\n",
      "ALC FREQ - Chi-square test statistic: 64.23548285408448\n",
      "ALC FREQ - P-value: 1.1257504443053055e-14\n"
     ]
    }
   ],
   "source": [
    "# get the %s of each category for alcohol frequency \n",
    "perc_alc_freq_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'alc_freq_filter'].value_counts(normalize=True)\n",
    "print('exp Percentages of alc freq')\n",
    "print(perc_alc_freq_d * 100)\n",
    "perc_alc_freq_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'alc_freq_filter'].value_counts(normalize=True)\n",
    "# print the value counts as percentages\n",
    "print('econtrol Percentages of alc freq')\n",
    "print(perc_alc_freq_c * 100)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['alc_freq_filter'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('ALC FREQ - Chi-square test statistic:', chi2_stat)\n",
    "print('ALC FREQ - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean screen time with exp cohort: 4.095172049402286\n",
      "Standard Deviation of screen time with exp cohort: 2.1654528679634337\n",
      "P-value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=5816505042.0, pvalue=0.0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = cevd_df_first_onlycevd[cevd_df_first_onlycevd['cevd_event'] == 1]\n",
    "mean_age = subset['full_screen_time'].mean()\n",
    "std_dev_age = subset['full_screen_time'].std()\n",
    "\n",
    "print(\"Mean screen time with exp cohort:\", mean_age)\n",
    "print(\"Standard Deviation of screen time with exp cohort:\", std_dev_age)\n",
    "print('P-value:')\n",
    "stats.mannwhitneyu(x=cevd_df_first_onlycevd['full_screen_time'], y=cevd_df_first_onlycevd['cevd_event'], alternative = 'two-sided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean screen with control cohort: 3.7692459943811807\n",
      "Standard Deviation of screenwith control cohort: 2.1503716063728913\n",
      "P-value:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=5816505042.0, pvalue=0.0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = cevd_df_first_onlycevd[cevd_df_first_onlycevd['cevd_event'] == 0]\n",
    "mean_age = subset['full_screen_time'].mean()\n",
    "std_dev_age = subset['full_screen_time'].std()\n",
    "\n",
    "print(\"Mean screen with control cohort:\", mean_age)\n",
    "print(\"Standard Deviation of screenwith control cohort:\", std_dev_age)\n",
    "print('P-value:')\n",
    "stats.mannwhitneyu(x=cevd_df_first_onlycevd['full_screen_time'], y=cevd_df_first_onlycevd['cevd_event'], alternative = 'two-sided')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent employment: 51.87239944521498\n",
      "exp Cohort Total employment: 1122.0\n",
      "Control Cohort Percent employment: 73.34346668101477\n",
      "Control Cohort Total employment: 54525.0\n",
      "employment - Chi-square test statistic: 469.3123170426571\n",
      "employment - P-value: 1.2306235154399097e-102\n"
     ]
    }
   ],
   "source": [
    "#get employment filter data\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'employ_status_array_filter'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'employ_status_array_filter'].sum()\n",
    "print('exp Cohort Percent employment:', percent_male_d)\n",
    "print('exp Cohort Total employment:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'employ_status_array_filter'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'employ_status_array_filter'].sum()\n",
    "print('Control Cohort Percent employment:', percent_male_c)\n",
    "print('Control Cohort Total employment:', male_sum_c)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['employ_status_array_filter'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for male data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('employment - Chi-square test statistic:', chi2_stat)\n",
    "print('employment - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Percentages of comorbid\n",
      "0    49.976884\n",
      "1    33.009709\n",
      "2    17.013407\n",
      "Name: comorb_sum_filter, dtype: float64\n",
      "CONTROL Percentages of comorbid\n",
      "0    68.010008\n",
      "1    23.611148\n",
      "2     8.378844\n",
      "Name: comorb_sum_filter, dtype: float64\n",
      "comorbid - Chi-square test statistic: 360.74757205587184\n",
      "comorbid - P-value: 4.6201922583704023e-79\n"
     ]
    }
   ],
   "source": [
    "# get comorbid filter data\n",
    "perc_alc_freq_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'comorb_sum_filter'].value_counts(normalize=True)\n",
    "print('exp Percentages of comorbid')\n",
    "print(perc_alc_freq_d * 100)\n",
    "perc_alc_freq_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'comorb_sum_filter'].value_counts(normalize=True)\n",
    "print('CONTROL Percentages of comorbid')\n",
    "print(perc_alc_freq_c * 100)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['comorb_sum_filter'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('comorbid - Chi-square test statistic:', chi2_stat)\n",
    "print('comorbid - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Percentages of acc wear month\n",
      "4    30.097087\n",
      "3    26.490985\n",
      "2    21.729080\n",
      "1    21.682848\n",
      "Name: acc_wearmonth, dtype: float64\n",
      "CONTROL Percentages of acc wear month\n",
      "4    29.568750\n",
      "3    26.269135\n",
      "2    22.923785\n",
      "1    21.238331\n",
      "Name: acc_wearmonth, dtype: float64\n",
      "acc wear month - Chi-square test statistic: 1.7437449650655716\n",
      "acc wear month - P-value: 0.6272524783297337\n"
     ]
    }
   ],
   "source": [
    "# get the accelerometer wear month data \n",
    "perc_alc_freq_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'acc_wearmonth'].value_counts(normalize=True)\n",
    "print('exp Percentages of acc wear month')\n",
    "print(perc_alc_freq_d * 100)\n",
    "perc_alc_freq_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'acc_wearmonth'].value_counts(normalize=True)\n",
    "# print the value counts as percentages\n",
    "print('CONTROL Percentages of acc wear month')\n",
    "print(perc_alc_freq_c * 100)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['acc_wearmonth'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('acc wear month - Chi-square test statistic:', chi2_stat)\n",
    "print('acc wear month - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp Cohort Percent depressed: 9.939898289412854\n",
      "exp Cohort Total depressed: 215\n",
      "Control Cohort Percent depressed: 8.77296817411423\n",
      "Control Cohort Total depressed: 6522\n",
      "depressed - Chi-square test statistic: 3.4202491662271077\n",
      "depressed - P-value: 0.06440129232624256\n"
     ]
    }
   ],
   "source": [
    "#get male/female data\n",
    "percent_male_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'dep_diag_yes'].mean() * 100\n",
    "male_sum_d = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 1, 'dep_diag_yes'].sum()\n",
    "print('exp Cohort Percent depressed:', percent_male_d)\n",
    "print('exp Cohort Total depressed:', male_sum_d)\n",
    "percent_male_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'dep_diag_yes'].mean() * 100\n",
    "male_sum_c = cevd_df_first_onlycevd.loc[cevd_df_first_onlycevd['cevd_event'] == 0, 'dep_diag_yes'].sum()\n",
    "print('Control Cohort Percent depressed:', percent_male_c)\n",
    "print('Control Cohort Total depressed:', male_sum_c)\n",
    "data = pd.crosstab(cevd_df_first_onlycevd['dep_diag_yes'], cevd_df_first_onlycevd['cevd_event']).to_numpy()\n",
    "# chi-square test for independence for male data\n",
    "chi2_stat, p_val, dof, expected = chi2_contingency(data)\n",
    "print('depressed - Chi-square test statistic:', chi2_stat)\n",
    "print('depressed - P-value:', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export data for accelerometer study to .csv file to transfer to R\n",
    "cevd_df_first.to_csv('cevd_first_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#person year calculation if needed\n",
    "#i69_days = cevd_df_first['i69_t2e'].sum()\n",
    "#i69_personyears = i69_days/365\n",
    "#print(i69_personyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensitivity analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74611"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all px on disability assistance\n",
    "cevd_df_noassist = cevd_df_first[cevd_df_first['gov_assistance_filter']==0]\n",
    "len(cevd_df_noassist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50749"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all px with comorbidities\n",
    "cevd_df_noassist_nocomor = cevd_df_noassist[cevd_df_noassist['comorb_sum_filter']==0]\n",
    "len(cevd_df_noassist_nocomor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cevd_df_noassist_nocomor.to_csv('cevd_first_model_sa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sensitivity analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter time to event for cevd for sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_cevd_t2e(value):\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    elif value < 1096:\n",
    "        return 1\n",
    "    elif 1096 <= value <= 1825:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "cevd_df_first['cevd_t2e_filter'] = cevd_df_first['cevd_t2e'].apply(filter_cevd_t2e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of px with no cevd: 74342\n"
     ]
    }
   ],
   "source": [
    "cevd_0 = cevd_df_first[cevd_df_first['cevd_t2e_filter']==0]\n",
    "print('Number of px with no cevd:',len(cevd_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of px with cevd within 3 years of accelerometer study: 636\n"
     ]
    }
   ],
   "source": [
    "cevd_1 = cevd_df_first[cevd_df_first['cevd_t2e_filter']==1]\n",
    "print('Number of px with cevd within 3 years of accelerometer study:',len(cevd_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of px with cevd between 3-5 years after accelerometer study: 524\n"
     ]
    }
   ],
   "source": [
    "cevd_2 = cevd_df_first[cevd_df_first['cevd_t2e_filter']==2]\n",
    "print('Number of px with cevd between 3-5 years after accelerometer study:',len(cevd_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of px with cevd 5 or more years after accelerometer study: 1003\n"
     ]
    }
   ],
   "source": [
    "cevd_3 = cevd_df_first[cevd_df_first['cevd_t2e_filter']==3]\n",
    "print('Number of px with cevd 5 or more years after accelerometer study:',len(cevd_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cevd_df_first.to_csv('cevd_first_model_sa_cevdt2e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean years from end of study to CeVD: 4.507348368260724\n",
      "std: 2.3530434375238425\n"
     ]
    }
   ],
   "source": [
    "mean_t2e_cevd = cevd_df_first['cevd_t2e'].mean()\n",
    "std_t2e_cevd = cevd_df_first['cevd_t2e'].std()\n",
    "\n",
    "print('mean years from end of study to CeVD:', (mean_t2e_cevd/365))\n",
    "print('std:', (std_t2e_cevd/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensitvity analysis 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_dep_dur(value):\n",
    "    if pd.isna(value):\n",
    "        return 0\n",
    "    elif value < 1896:\n",
    "        return 1\n",
    "    elif 1896 <= value <= 3650:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "cevd_df_first['dep_dur_filter'] = cevd_df_first['dep_dur'].apply(filter_dep_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients without depression diagnosis prior to accelerometer study: 68186\n"
     ]
    }
   ],
   "source": [
    "dep_0 = cevd_df_first[cevd_df_first['dep_dur_filter']==0]\n",
    "print('number of patients without depression diagnosis prior to accelerometer study:', len(dep_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients with depression diagnosis within 5 yrs before accelerometer study: 2450\n"
     ]
    }
   ],
   "source": [
    "dep_1 = cevd_df_first[cevd_df_first['dep_dur_filter']==1]\n",
    "print('number of patients with depression diagnosis within 5 yrs before accelerometer study:', len(dep_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients with depression diagnosis conferred between 5 and 10 yrs before accelerometer study: 1326\n"
     ]
    }
   ],
   "source": [
    "dep_2 = cevd_df_first[cevd_df_first['dep_dur_filter']==2]\n",
    "print('number of patients with depression diagnosis conferred between 5 and 10 yrs before accelerometer study:', len(dep_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients with depression diagnosis conferred 10 or more yrs before accelerometer study: 4543\n"
     ]
    }
   ],
   "source": [
    "dep_3 = cevd_df_first[cevd_df_first['dep_dur_filter']==3]\n",
    "print('number of patients with depression diagnosis conferred 10 or more yrs before accelerometer study:', len(dep_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean years from dep diag to start of study: 13.539068348243912\n",
      "std: 14.262918013429811\n"
     ]
    }
   ],
   "source": [
    "mean_t2e_dep = cevd_df_first['dep_dur'].mean()\n",
    "std_t2e_dep = cevd_df_first['dep_dur'].std()\n",
    "\n",
    "print('mean years from dep diag to start of study:', (mean_t2e_dep/365))\n",
    "print('std:', (std_t2e_dep/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cevd_df_first.to_csv('cevd_first_model_sa_cevdt2eanddep.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#to upload on RAP UKBB\n",
    "#%%bash\n",
    "#dx upload <insert file name here>.ipynb --dest /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
